{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from helper.model import WordLSTM\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath,map_location=lambda storage, loc: storage)\n",
    "    model = checkpoint['model']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    for parameter in model.parameters():\n",
    "        parameter.requires_grad = False\n",
    "\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = WordLSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_MODEL_PATH = '/home/taindp/VINBRAIN_INTERNSHIP/nlg_lstm/model'\n",
    "_RESOURCE_PATH = '/home/taindp/VINBRAIN_INTERNSHIP/nlg_lstm/resource'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2int = torch.load(os.path.join(_RESOURCE_PATH,'token2int.h5'))\n",
    "int2token = torch.load(os.path.join(_RESOURCE_PATH,'int2token.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = load_checkpoint(os.path.join(_MODEL_PATH,'checkpoint.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordLSTM(\n",
       "  (emb_layer): Embedding(16592, 200)\n",
       "  (lstm): LSTM(200, 256, num_layers=4, batch_first=True, dropout=0.3)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc): Linear(in_features=256, out_features=16592, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(net,tkn,h=None):\n",
    "    \n",
    "    x = np.array([[token2int[tkn]]])\n",
    "    inputs = torch.from_numpy(x)\n",
    "    \n",
    "#     inputs = inputs.cuda()\n",
    "    h = tuple([each.data for each in h])\n",
    "    \n",
    "    out,h = net(inputs,h)\n",
    "    \n",
    "    p = F.softmax(out,dim=1).data\n",
    "    \n",
    "#     p = p.cuda()\n",
    "    p = p.numpy()\n",
    "    p = p.reshape(p.shape[1],)\n",
    "    \n",
    "    top_n_idx = p.argsort()[-3:][::-1]\n",
    "    \n",
    "    sampled_token_index = top_n_idx[random.sample([0,1,2],1)[0]]\n",
    "    \n",
    "    return int2token[sampled_token_index],h\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(net,size,prime='it is'):\n",
    "#     net.cuda()\n",
    "    net.eval()\n",
    "    \n",
    "    h = net.init_hidden(1)\n",
    "    toks = prime.split()\n",
    "    \n",
    "    #predict next token\n",
    "    \n",
    "    for t in prime.split():\n",
    "        token,h = predict(net,t,h)\n",
    "        \n",
    "    toks.append(token)\n",
    "    \n",
    "    for i in range(size-1):\n",
    "        token,h = predict(net,toks[-1],h)\n",
    "        toks.append(token)\n",
    "    return ' '.join(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one of the stowaway postcard paragraphwith wilderness struggle jamie postcard expels like lala mattered understanding inhabitant lacks carrol'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(net,15,prime = 'one of the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one of the stowaway postcard paragraphwith wilderness struggle'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(net,5,prime = 'one of the')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
